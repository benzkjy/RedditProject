{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from random import random, sample, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9gx68l</td>\n",
       "      <td>Reddit, how would you feel about a law that ba...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>261</td>\n",
       "      <td>149070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9hef7a</td>\n",
       "      <td>In a video game, if you come across an empty r...</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>263</td>\n",
       "      <td>83296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9icx7a</td>\n",
       "      <td>What is a website that everyone should know ab...</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>82665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9jlras</td>\n",
       "      <td>What could the U.S.A. have spent $1,000,000,00...</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>271</td>\n",
       "      <td>74998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9fbka2</td>\n",
       "      <td>If a genie grants you the opportunity to ejacu...</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>69915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  hour  minute  \\\n",
       "0  9gx68l  Reddit, how would you feel about a law that ba...    14       1   \n",
       "1  9hef7a  In a video game, if you come across an empty r...     7      17   \n",
       "2  9icx7a  What is a website that everyone should know ab...    19      16   \n",
       "3  9jlras  What could the U.S.A. have spent $1,000,000,00...     6      17   \n",
       "4  9fbka2  If a genie grants you the opportunity to ejacu...    16      47   \n",
       "\n",
       "   dayofweek  dayofyear   score  \n",
       "0          2        261  149070  \n",
       "1          4        263   83296  \n",
       "2          0        266   82665  \n",
       "3          5        271   74998  \n",
       "4          3        255   69915  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>503938.000000</td>\n",
       "      <td>503938.000000</td>\n",
       "      <td>503938.000000</td>\n",
       "      <td>503938.000000</td>\n",
       "      <td>503938.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.781120</td>\n",
       "      <td>29.562274</td>\n",
       "      <td>2.911717</td>\n",
       "      <td>274.629046</td>\n",
       "      <td>25.797312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.602338</td>\n",
       "      <td>17.317721</td>\n",
       "      <td>1.969925</td>\n",
       "      <td>17.578185</td>\n",
       "      <td>815.115481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>149070.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                hour         minute      dayofweek      dayofyear  \\\n",
       "count  503938.000000  503938.000000  503938.000000  503938.000000   \n",
       "mean       12.781120      29.562274       2.911717     274.629046   \n",
       "std         6.602338      17.317721       1.969925      17.578185   \n",
       "min         0.000000       0.000000       0.000000     243.000000   \n",
       "25%         8.000000      15.000000       1.000000     260.000000   \n",
       "50%        13.000000      30.000000       3.000000     275.000000   \n",
       "75%        18.000000      45.000000       5.000000     290.000000   \n",
       "max        23.000000      59.000000       6.000000     304.000000   \n",
       "\n",
       "               score  \n",
       "count  503938.000000  \n",
       "mean       25.797312  \n",
       "std       815.115481  \n",
       "min         0.000000  \n",
       "25%         1.000000  \n",
       "50%         1.000000  \n",
       "75%         3.000000  \n",
       "max    149070.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = df['title'].values.tolist()\n",
    "hours = df['hour'].values.tolist()\n",
    "minutes = df['minute'].values.tolist()\n",
    "dayofweeks = df['dayofweek'].values.tolist()\n",
    "dayofyears = df['dayofyear'].values.tolist()\n",
    "is_top_submission = df['score'].values.tolist()\n",
    "split_score = is_top_submission[np.int(len(is_top_submission)/2)]\n",
    "for i in range(0,len(is_top_submission)):\n",
    "  if is_top_submission[i] > split_score:\n",
    "    is_top_submission[i] = 1\n",
    "  else:\n",
    "    is_top_submission[i] = 0\n",
    "\n",
    "titles = np.array(titles)\n",
    "hours = np.array(hours, dtype=int)\n",
    "minutes = np.array(minutes, dtype=int)\n",
    "dayofweeks = np.array(dayofweeks, dtype=int)\n",
    "dayofyears = np.array(dayofyears, dtype=int)\n",
    "is_top_submission = np.array(is_top_submission, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reddit, how would you feel about a law that bans radio stations from playing commercials with honking/beeping/siren noises in them?'\n",
      " 'In a video game, if you come across an empty room with a health pack, extra ammo, and a save point, you know some serious shit is about to go down. What is the real-life equivalent of this?']\n",
      "(503938,)\n",
      "[14  7]\n",
      "[ 1 17]\n",
      "[2 4]\n",
      "[261 263]\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "print(titles[0:2])\n",
    "print(titles.shape)\n",
    "print(hours[0:2])\n",
    "print(minutes[0:2])\n",
    "print(dayofweeks[0:2])\n",
    "print(dayofyears[0:2])\n",
    "print(is_top_submission[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('reddit', 59327), ('how', 68884), ('would', 58961), ('you', 320628), ('feel', 9795), (\n",
      "{'icles': 76310, 'expereiced': 66467, 'applies': 6525, 'sourced': 17409, 'molton': 59417, 'ppÂ£d': 56\n",
      "78801\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "\n",
    "max_features = 40000\n",
    "\n",
    "word_tokenizer = Tokenizer(max_features)\n",
    "word_tokenizer.fit_on_texts(titles)\n",
    "\n",
    "print(str(word_tokenizer.word_counts)[0:100])\n",
    "print(str(word_tokenizer.word_index)[0:100])\n",
    "print(len(word_tokenizer.word_counts))   # true word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 15, 19, 1, 95, 33, 5, 472, 12, 4055, 1749, 4425, 46, 621, 2745, 25, 11387, 10732, 11388, 5041, 11, 87]\n"
     ]
    }
   ],
   "source": [
    "titles_tf = word_tokenizer.texts_to_sequences(titles)\n",
    "print(titles_tf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   19     1    95    33     5   472    12  4055  1749  4425    46   621\n",
      "  2745    25 11387 10732 11388  5041    11    87]\n"
     ]
    }
   ],
   "source": [
    "maxlen = 20\n",
    "titles_tf = sequence.pad_sequences(titles_tf, maxlen=maxlen)\n",
    "print(titles_tf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_path = 'glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0919e-03  3.3324e-01  3.5743e-01 -5.4041e-01  8.2032e-01 -4.9391e-01\n",
      " -3.2588e-01  1.9972e-03 -2.3829e-01  3.5554e-01 -6.0655e-01  9.8932e-01\n",
      " -2.1786e-01  1.1236e-01  1.1494e+00  7.3284e-01  5.1182e-01  2.9287e-01\n",
      "  2.8388e-01 -1.3590e+00 -3.7951e-01  5.0943e-01  7.0710e-01  6.2941e-01\n",
      "  1.0534e+00 -2.1756e+00 -1.3204e+00  4.0001e-01  1.5741e+00 -1.6600e+00\n",
      "  3.7721e+00  8.6949e-01 -8.0439e-01  1.8390e-01 -3.4332e-01  1.0714e-02\n",
      "  2.3969e-01  6.6748e-02  7.0117e-01 -7.3702e-01  2.0877e-01  1.1564e-01\n",
      " -1.5190e-01  8.5908e-01  2.2620e-01  1.6519e-01  3.6309e-01 -4.5697e-01\n",
      " -4.8969e-02  1.1316e+00]\n"
     ]
    }
   ],
   "source": [
    "embedding_vectors = {}\n",
    "\n",
    "with open(embeddings_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line_split = line.strip().split(\" \")\n",
    "        vec = np.array(line_split[1:], dtype=float)\n",
    "        word = line_split[0]\n",
    "        embedding_vectors[word] = vec\n",
    "        \n",
    "print(embedding_vectors['you'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00]\n",
      " [-1.0919e-03  3.3324e-01  3.5743e-01 -5.4041e-01  8.2032e-01 -4.9391e-01\n",
      "  -3.2588e-01  1.9972e-03 -2.3829e-01  3.5554e-01 -6.0655e-01  9.8932e-01\n",
      "  -2.1786e-01  1.1236e-01  1.1494e+00  7.3284e-01  5.1182e-01  2.9287e-01\n",
      "   2.8388e-01 -1.3590e+00 -3.7951e-01  5.0943e-01  7.0710e-01  6.2941e-01\n",
      "   1.0534e+00 -2.1756e+00 -1.3204e+00  4.0001e-01  1.5741e+00 -1.6600e+00\n",
      "   3.7721e+00  8.6949e-01 -8.0439e-01  1.8390e-01 -3.4332e-01  1.0714e-02\n",
      "   2.3969e-01  6.6748e-02  7.0117e-01 -7.3702e-01  2.0877e-01  1.1564e-01\n",
      "  -1.5190e-01  8.5908e-01  2.2620e-01  1.6519e-01  3.6309e-01 -4.5697e-01\n",
      "  -4.8969e-02  1.1316e+00]]\n"
     ]
    }
   ],
   "source": [
    "weights_matrix = np.zeros((max_features + 1, 50))\n",
    "\n",
    "for word, i in word_tokenizer.word_index.items():\n",
    "\n",
    "    embedding_vector = embedding_vectors.get(word)\n",
    "    if embedding_vector is not None and i <= max_features:\n",
    "        weights_matrix[i] = embedding_vector\n",
    "\n",
    "# index 0 vector should be all zeroes, index 1 vector should be the same one as above\n",
    "print(weights_matrix[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[261 263 266 271 255 300 274 258 271 295]\n"
     ]
    }
   ],
   "source": [
    "dayofyears_tf = dayofyears\n",
    "print(dayofyears_tf[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Input, Model\n",
    "from keras.layers import Dense, Embedding, GlobalAveragePooling1D, concatenate, Activation\n",
    "from keras.layers.core import Masking, Dropout, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "epochs = 20\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles_input = Input(shape=(maxlen,), name='titles_input')\n",
    "titles_embedding = Embedding(max_features + 1, embedding_dims, weights=[weights_matrix])(titles_input)\n",
    "titles_pooling = GlobalAveragePooling1D()(titles_embedding)\n",
    "titles_dropout = Dropout(dropout_rate)(titles_pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aux_output = Dense(1, activation='sigmoid', name='aux_out')(titles_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_embedding_dims = 64\n",
    "\n",
    "hours_input = Input(shape=(1,), name='hours_input')\n",
    "hours_embedding = Embedding(24, meta_embedding_dims)(hours_input)\n",
    "hours_reshape = Reshape((meta_embedding_dims,))(hours_embedding)\n",
    "\n",
    "dayofweeks_input = Input(shape=(1,), name='dayofweeks_input')\n",
    "dayofweeks_embedding = Embedding(7, meta_embedding_dims)(dayofweeks_input)\n",
    "dayofweeks_reshape = Reshape((meta_embedding_dims,))(dayofweeks_embedding)\n",
    "\n",
    "minutes_input = Input(shape=(1,), name='minutes_input')\n",
    "minutes_embedding = Embedding(60, meta_embedding_dims)(minutes_input)\n",
    "minutes_reshape = Reshape((meta_embedding_dims,))(minutes_embedding)\n",
    "\n",
    "dayofyears_input = Input(shape=(1,), name='dayofyears_input')\n",
    "dayofyears_embedding = Embedding(366, meta_embedding_dims)(dayofyears_input)\n",
    "dayofyears_reshape = Reshape((meta_embedding_dims,))(dayofyears_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = concatenate([titles_dropout, hours_reshape, dayofweeks_reshape, minutes_reshape, dayofyears_reshape])\n",
    "\n",
    "hidden_1 = Dense(256, activation='relu')(merged)\n",
    "hidden_1 = BatchNormalization()(hidden_1)\n",
    "\n",
    "main_output = Dense(1, activation='sigmoid', name='main_out')(hidden_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "titles_input (InputLayer)       (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 50)       2000050     titles_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "hours_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dayofweeks_input (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "minutes_input (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dayofyears_input (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 50)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 64)        1536        hours_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 64)        448         dayofweeks_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 64)        3840        minutes_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 64)        23424       dayofyears_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50)           0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 64)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 64)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 64)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 64)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 306)          0           dropout_1[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          78592       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_out (Dense)                (None, 1)            257         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "aux_out (Dense)                 (None, 1)            51          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,109,222\n",
      "Trainable params: 2,108,710\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[titles_input,\n",
    "                      hours_input,\n",
    "                      dayofweeks_input,\n",
    "                      minutes_input,\n",
    "                      dayofyears_input], outputs=[main_output, aux_output])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'],\n",
    "              loss_weights=[1, 0.2])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed(123)\n",
    "split = 0.2\n",
    "\n",
    "# returns randomized indices with no repeats\n",
    "idx = sample(range(titles_tf.shape[0]), titles_tf.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles_tf = titles_tf[idx, :]\n",
    "hours = hours[idx]\n",
    "dayofweeks = dayofweeks[idx]\n",
    "minutes = minutes[idx]\n",
    "dayofyears_tf = dayofyears_tf[idx]\n",
    "is_top_submission = is_top_submission[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5835871689801264\n"
     ]
    }
   ],
   "source": [
    "print(1 - np.mean(is_top_submission[:(int(titles_tf.shape[0] * split))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger,EarlyStopping\n",
    "\n",
    "csv_logger = CSVLogger('training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 403150 samples, validate on 100788 samples\n",
      "Epoch 1/20\n",
      "403150/403150 [==============================] - 131s 326us/step - loss: 0.7311 - main_out_loss: 0.6077 - aux_out_loss: 0.6167 - main_out_acc: 0.6383 - aux_out_acc: 0.6357 - val_loss: 0.7022 - val_main_out_loss: 0.5827 - val_aux_out_loss: 0.5975 - val_main_out_acc: 0.6617 - val_aux_out_acc: 0.6516\n",
      "Epoch 2/20\n",
      "403150/403150 [==============================] - 130s 322us/step - loss: 0.7000 - main_out_loss: 0.5813 - aux_out_loss: 0.5934 - main_out_acc: 0.6632 - aux_out_acc: 0.6587 - val_loss: 0.6977 - val_main_out_loss: 0.5785 - val_aux_out_loss: 0.5958 - val_main_out_acc: 0.6656 - val_aux_out_acc: 0.6583\n",
      "Epoch 3/20\n",
      "403150/403150 [==============================] - 129s 321us/step - loss: 0.6887 - main_out_loss: 0.5713 - aux_out_loss: 0.5869 - main_out_acc: 0.6722 - aux_out_acc: 0.6667 - val_loss: 0.6952 - val_main_out_loss: 0.5759 - val_aux_out_loss: 0.5962 - val_main_out_acc: 0.6652 - val_aux_out_acc: 0.6586\n",
      "Epoch 4/20\n",
      "403150/403150 [==============================] - 131s 324us/step - loss: 0.6809 - main_out_loss: 0.5643 - aux_out_loss: 0.5827 - main_out_acc: 0.6793 - aux_out_acc: 0.6721 - val_loss: 0.6960 - val_main_out_loss: 0.5765 - val_aux_out_loss: 0.5971 - val_main_out_acc: 0.6655 - val_aux_out_acc: 0.6590\n",
      "Epoch 5/20\n",
      "403150/403150 [==============================] - 131s 326us/step - loss: 0.6752 - main_out_loss: 0.5592 - aux_out_loss: 0.5800 - main_out_acc: 0.6839 - aux_out_acc: 0.6751 - val_loss: 0.6968 - val_main_out_loss: 0.5771 - val_aux_out_loss: 0.5983 - val_main_out_acc: 0.6647 - val_aux_out_acc: 0.6611\n",
      "Epoch 6/20\n",
      "403150/403150 [==============================] - 130s 322us/step - loss: 0.6696 - main_out_loss: 0.5541 - aux_out_loss: 0.5775 - main_out_acc: 0.6891 - aux_out_acc: 0.6781 - val_loss: 0.6978 - val_main_out_loss: 0.5778 - val_aux_out_loss: 0.5997 - val_main_out_acc: 0.6630 - val_aux_out_acc: 0.6560\n",
      "Epoch 7/20\n",
      "403150/403150 [==============================] - 131s 324us/step - loss: 0.6654 - main_out_loss: 0.5503 - aux_out_loss: 0.5755 - main_out_acc: 0.6924 - aux_out_acc: 0.6805 - val_loss: 0.6986 - val_main_out_loss: 0.5785 - val_aux_out_loss: 0.6004 - val_main_out_acc: 0.6652 - val_aux_out_acc: 0.6582\n",
      "Epoch 8/20\n",
      "403150/403150 [==============================] - 130s 324us/step - loss: 0.6614 - main_out_loss: 0.5466 - aux_out_loss: 0.5740 - main_out_acc: 0.6972 - aux_out_acc: 0.6830 - val_loss: 0.7007 - val_main_out_loss: 0.5802 - val_aux_out_loss: 0.6021 - val_main_out_acc: 0.6643 - val_aux_out_acc: 0.6594\n",
      "Epoch 9/20\n",
      "403150/403150 [==============================] - 131s 325us/step - loss: 0.6573 - main_out_loss: 0.5428 - aux_out_loss: 0.5724 - main_out_acc: 0.6998 - aux_out_acc: 0.6849 - val_loss: 0.7030 - val_main_out_loss: 0.5826 - val_aux_out_loss: 0.6023 - val_main_out_acc: 0.6629 - val_aux_out_acc: 0.6576\n",
      "Epoch 10/20\n",
      "403150/403150 [==============================] - 130s 323us/step - loss: 0.6541 - main_out_loss: 0.5398 - aux_out_loss: 0.5713 - main_out_acc: 0.7030 - aux_out_acc: 0.6861 - val_loss: 0.7046 - val_main_out_loss: 0.5840 - val_aux_out_loss: 0.6033 - val_main_out_acc: 0.6631 - val_aux_out_acc: 0.6567\n",
      "Epoch 11/20\n",
      "403150/403150 [==============================] - 131s 326us/step - loss: 0.6500 - main_out_loss: 0.5360 - aux_out_loss: 0.5700 - main_out_acc: 0.7055 - aux_out_acc: 0.6871 - val_loss: 0.7058 - val_main_out_loss: 0.5849 - val_aux_out_loss: 0.6043 - val_main_out_acc: 0.6613 - val_aux_out_acc: 0.6546\n",
      "Epoch 12/20\n",
      "403150/403150 [==============================] - 132s 329us/step - loss: 0.6473 - main_out_loss: 0.5334 - aux_out_loss: 0.5693 - main_out_acc: 0.7081 - aux_out_acc: 0.6879 - val_loss: 0.7073 - val_main_out_loss: 0.5863 - val_aux_out_loss: 0.6052 - val_main_out_acc: 0.6623 - val_aux_out_acc: 0.6548\n",
      "Epoch 13/20\n",
      "403150/403150 [==============================] - 131s 325us/step - loss: 0.6435 - main_out_loss: 0.5298 - aux_out_loss: 0.5686 - main_out_acc: 0.7115 - aux_out_acc: 0.6890 - val_loss: 0.7078 - val_main_out_loss: 0.5868 - val_aux_out_loss: 0.6052 - val_main_out_acc: 0.6611 - val_aux_out_acc: 0.6565\n",
      "Epoch 14/20\n",
      "403150/403150 [==============================] - 132s 327us/step - loss: 0.6401 - main_out_loss: 0.5265 - aux_out_loss: 0.5679 - main_out_acc: 0.7140 - aux_out_acc: 0.6892 - val_loss: 0.7136 - val_main_out_loss: 0.5924 - val_aux_out_loss: 0.6061 - val_main_out_acc: 0.6595 - val_aux_out_acc: 0.6536\n",
      "Epoch 15/20\n",
      "403150/403150 [==============================] - 131s 325us/step - loss: 0.6364 - main_out_loss: 0.5230 - aux_out_loss: 0.5671 - main_out_acc: 0.7165 - aux_out_acc: 0.6900 - val_loss: 0.7130 - val_main_out_loss: 0.5917 - val_aux_out_loss: 0.6066 - val_main_out_acc: 0.6579 - val_aux_out_acc: 0.6531\n",
      "Epoch 16/20\n",
      "403150/403150 [==============================] - 131s 326us/step - loss: 0.6332 - main_out_loss: 0.5199 - aux_out_loss: 0.5663 - main_out_acc: 0.7190 - aux_out_acc: 0.6910 - val_loss: 0.7189 - val_main_out_loss: 0.5973 - val_aux_out_loss: 0.6080 - val_main_out_acc: 0.6554 - val_aux_out_acc: 0.6552\n",
      "Epoch 17/20\n",
      "403150/403150 [==============================] - 131s 324us/step - loss: 0.6301 - main_out_loss: 0.5169 - aux_out_loss: 0.5658 - main_out_acc: 0.7224 - aux_out_acc: 0.6919 - val_loss: 0.7204 - val_main_out_loss: 0.5987 - val_aux_out_loss: 0.6086 - val_main_out_acc: 0.6582 - val_aux_out_acc: 0.6544\n",
      "Epoch 18/20\n",
      "403150/403150 [==============================] - 130s 323us/step - loss: 0.6265 - main_out_loss: 0.5134 - aux_out_loss: 0.5653 - main_out_acc: 0.7250 - aux_out_acc: 0.6918 - val_loss: 0.7287 - val_main_out_loss: 0.6067 - val_aux_out_loss: 0.6102 - val_main_out_acc: 0.6540 - val_aux_out_acc: 0.6557\n",
      "Epoch 19/20\n",
      "403150/403150 [==============================] - 132s 327us/step - loss: 0.6220 - main_out_loss: 0.5090 - aux_out_loss: 0.5648 - main_out_acc: 0.7283 - aux_out_acc: 0.6923 - val_loss: 0.7278 - val_main_out_loss: 0.6059 - val_aux_out_loss: 0.6098 - val_main_out_acc: 0.6574 - val_aux_out_acc: 0.6556\n",
      "Epoch 20/20\n",
      "403150/403150 [==============================] - 130s 323us/step - loss: 0.6180 - main_out_loss: 0.5052 - aux_out_loss: 0.5643 - main_out_acc: 0.7314 - aux_out_acc: 0.6926 - val_loss: 0.7308 - val_main_out_loss: 0.6091 - val_aux_out_loss: 0.6089 - val_main_out_acc: 0.6571 - val_aux_out_acc: 0.6538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b3c69e6a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([titles_tf, hours, dayofweeks, minutes, dayofyears_tf], [is_top_submission, is_top_submission],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=split, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_text(text, maxlen):\n",
    "    encoded = word_tokenizer.texts_to_sequences([text])\n",
    "    return sequence.pad_sequences(encoded, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0   69 8557 1049   19 2649  137   22    1\n",
      "  1697    5 1459   46  291  729]]\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Which movie's plot would drastically change if you removed a letter from its title?\"\n",
    "encoded_text = encode_text(input_text, maxlen)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.58657765]], dtype=float32), array([[0.5020961]], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_hour = np.array([15])\n",
    "input_minute = np.array([10])\n",
    "input_dayofweek = np.array([1])\n",
    "input_dayofyear = np.array([16 - 1])\n",
    "\n",
    "model.predict([encoded_text, input_hour, input_dayofweek, input_minute, input_dayofyear])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.60986346]], dtype=float32), array([[0.61377]], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"What is perfectly legal but creepy as hell?\"\n",
    "encoded_text = encode_text(input_text, maxlen)\n",
    "model.predict([encoded_text, input_hour, input_dayofweek, input_minute, input_dayofyear])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.6107462]\n",
      "['What', 'is', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.49745703]\n",
      "['What', 'is', 'perfectly', 'but', 'creepy', 'as', 'hell?'] [0.622355]\n",
      "['What', 'is', 'perfectly', 'legal', 'creepy', 'as', 'hell?'] [0.57864136]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'as', 'hell?'] [0.5981729]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'hell?'] [0.61045]\n",
      "After Change :  What is perfectly but creepy as hell? [ 0.622355 ]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "word_list = input_text.split(\" \")\n",
    "final_text = \"\"\n",
    "max_score = int(0)\n",
    "for i in range(len(word_list)):\n",
    "    temp_list = word_list[:]\n",
    "    if(i != 0 and i != len(word_list)-1 ): # probably not gonna remove first word and last word\n",
    "        del temp_list[i]\n",
    "        temp_text = \" \".join(temp_list)\n",
    "        encoded_text = encode_text(temp_text, maxlen)\n",
    "        predict_score = model.predict([encoded_text, input_hour, input_dayofweek, input_minute, input_dayofyear])\n",
    "        print(temp_list,predict_score[1][0])\n",
    "       \n",
    "        if (max_score - predict_score[1][0][0] < 0):\n",
    "            max_score = predict_score[1][0][0]\n",
    "            final_text = temp_text\n",
    "print(\"After Change : \",final_text, \"[\", max_score,\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def synonym(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lm in syn.lemmas():\n",
    "            synonyms.append(lm.name())\n",
    "    return list(set(synonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['perfectly', 'absolutely', 'utterly', 'dead']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym('perfectly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'equal', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.57594705]\n",
      "['What', 'make_up', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.6111701]\n",
      "['What', 'embody', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.6567825]\n",
      "['What', 'cost', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.53797853]\n",
      "['What', 'be', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.6171254]\n",
      "['What', 'live', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.61468846]\n",
      "['What', 'exist', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.6437134]\n",
      "['What', 'follow', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.6050839]\n",
      "['What', 'personify', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.6348581]\n",
      "['What', 'constitute', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.6250751]\n",
      "['What', 'represent', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.62024385]\n",
      "['What', 'comprise', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.56736124]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.61419266]\n",
      "['What', 'is', 'absolutely', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.55061495]\n",
      "['What', 'is', 'utterly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.5887527]\n",
      "['What', 'is', 'dead', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.51812685]\n",
      "['What', 'is', 'perfectly', 'effectual', 'but', 'creepy', 'as', 'hell?'] [0.6227741]\n",
      "['What', 'is', 'perfectly', 'sound', 'but', 'creepy', 'as', 'hell?'] [0.664157]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.61419266]\n",
      "['What', 'is', 'perfectly', 'legal', 'simply', 'creepy', 'as', 'hell?'] [0.5521745]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.61419266]\n",
      "['What', 'is', 'perfectly', 'legal', 'merely', 'creepy', 'as', 'hell?'] [0.5013197]\n",
      "['What', 'is', 'perfectly', 'legal', 'just', 'creepy', 'as', 'hell?'] [0.58386785]\n",
      "['What', 'is', 'perfectly', 'legal', 'only', 'creepy', 'as', 'hell?'] [0.58047074]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy-crawly', 'as', 'hell?'] [0.5986015]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.61419266]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'group_A', 'hell?'] [0.6108741]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'atomic_number_33', 'hell?'] [0.6108741]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'every_bit', 'hell?'] [0.6108741]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'American_Samoa', 'hell?'] [0.6108741]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'ampere', 'hell?'] [0.6108741]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'A', 'hell?'] [0.61095434]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'angstrom_unit', 'hell?'] [0.6108741]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'As', 'hell?'] [0.61419266]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'as', 'hell?'] [0.61419266]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'angstrom', 'hell?'] [0.6108741]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'vitamin_A', 'hell?'] [0.6108741]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'arsenic', 'hell?'] [0.6757259]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'axerophthol', 'hell?'] [0.6108741]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'antiophthalmic_factor', 'hell?'] [0.6108741]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'amp', 'hell?'] [0.5675191]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'Eastern_Samoa', 'hell?'] [0.6108741]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'deoxyadenosine_monophosphate', 'hell?'] [0.6108741]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'a', 'hell?'] [0.61095434]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'adenine', 'hell?'] [0.6108741]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'AS', 'hell?'] [0.61419266]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'equally', 'hell?'] [0.7690026]\n",
      "['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'type_A', 'hell?'] [0.6108741]\n",
      "After Change :  ['What', 'is', 'perfectly', 'legal', 'but', 'creepy', 'type_A', 'hell?'] [ 0.7690026 ]\n"
     ]
    }
   ],
   "source": [
    "final_text = \"\"\n",
    "max_score = int(0)\n",
    "for i in range(len(word_list)):\n",
    "    temp_list = word_list[:]\n",
    "    syno = synonym(temp_list[i])\n",
    "    for j in range(len(syno)):\n",
    "        temp_list[i] = syno[j]\n",
    "        encoded_text = encode_text(temp_list, maxlen)\n",
    "        predict_score = model.predict([encoded_text, input_hour, input_dayofweek, input_minute, input_dayofyear])\n",
    "        print(temp_list,predict_score[1][0])\n",
    "        \n",
    "        if (max_score - predict_score[1][0][0] < 0):\n",
    "            max_score = predict_score[1][0][0]\n",
    "            final_text = temp_list\n",
    "print(\"After Change : \",final_text, \"[\", max_score,\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
