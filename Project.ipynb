{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from random import random, sample, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9gx68l</td>\n",
       "      <td>Reddit, how would you feel about a law that ba...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>261</td>\n",
       "      <td>149070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9hef7a</td>\n",
       "      <td>In a video game, if you come across an empty r...</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>263</td>\n",
       "      <td>83296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9icx7a</td>\n",
       "      <td>What is a website that everyone should know ab...</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>82665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9jlras</td>\n",
       "      <td>What could the U.S.A. have spent $1,000,000,00...</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>271</td>\n",
       "      <td>74998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9fbka2</td>\n",
       "      <td>If a genie grants you the opportunity to ejacu...</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>69915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  hour  minute  \\\n",
       "0  9gx68l  Reddit, how would you feel about a law that ba...    14       1   \n",
       "1  9hef7a  In a video game, if you come across an empty r...     7      17   \n",
       "2  9icx7a  What is a website that everyone should know ab...    19      16   \n",
       "3  9jlras  What could the U.S.A. have spent $1,000,000,00...     6      17   \n",
       "4  9fbka2  If a genie grants you the opportunity to ejacu...    16      47   \n",
       "\n",
       "   dayofweek  dayofyear   score  \n",
       "0          2        261  149070  \n",
       "1          4        263   83296  \n",
       "2          0        266   82665  \n",
       "3          5        271   74998  \n",
       "4          3        255   69915  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.429750</td>\n",
       "      <td>29.606687</td>\n",
       "      <td>2.944250</td>\n",
       "      <td>273.943562</td>\n",
       "      <td>758.115937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.749771</td>\n",
       "      <td>17.346100</td>\n",
       "      <td>1.996939</td>\n",
       "      <td>17.597535</td>\n",
       "      <td>4513.724777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>149070.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               hour        minute     dayofweek     dayofyear          score\n",
       "count  16000.000000  16000.000000  16000.000000  16000.000000   16000.000000\n",
       "mean      12.429750     29.606687      2.944250    273.943562     758.115937\n",
       "std        6.749771     17.346100      1.996939     17.597535    4513.724777\n",
       "min        0.000000      0.000000      0.000000    243.000000      10.000000\n",
       "25%        7.000000     15.000000      1.000000    259.000000      13.000000\n",
       "50%       13.000000     30.000000      3.000000    274.000000      20.000000\n",
       "75%       18.000000     45.000000      5.000000    290.000000      57.000000\n",
       "max       23.000000     59.000000      6.000000    304.000000  149070.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_titles = df['title'].values.tolist()\n",
    "s_hours = df['hour'].values.tolist()\n",
    "s_minutes = df['minute'].values.tolist()\n",
    "s_dayofweeks = df['dayofweek'].values.tolist()\n",
    "s_dayofyears = df['dayofyear'].values.tolist()\n",
    "s_is_top_submission = df['score'].values.tolist()\n",
    "split_score = s_is_top_submission[np.int(len(s_is_top_submission)/2)]\n",
    "for i in range(0,len(s_is_top_submission)):\n",
    "  if s_is_top_submission[i] > split_score:\n",
    "    s_is_top_submission[i] = 1\n",
    "  else:\n",
    "    s_is_top_submission[i] = 0\n",
    "\n",
    "titles = np.array(s_titles)\n",
    "hours = np.array(s_hours, dtype=int)\n",
    "minutes = np.array(s_minutes, dtype=int)\n",
    "dayofweeks = np.array(s_dayofweeks, dtype=int)\n",
    "dayofyears = np.array(s_dayofyears, dtype=int)\n",
    "is_top_submission = np.array(s_is_top_submission, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'Reddit, how would you feel about a law that bans radio stations from playing commercials with honking/beeping/siren noises in them?'\n",
      " 'In a video game, if you come across an empty room with a health pack, extra ammo, and a save point, you know some serious shit is about to go down. What is the real-life equivalent of this?']\n",
      "(16000,)\n",
      "[14  7]\n",
      "[ 1 17]\n",
      "[2 4]\n",
      "[261 263]\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "print(titles[0:2])\n",
    "print(titles.shape)\n",
    "print(hours[0:2])\n",
    "print(minutes[0:2])\n",
    "print(dayofweeks[0:2])\n",
    "print(dayofyears[0:2])\n",
    "print(is_top_submission[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('reddit', 2146), ('how', 1788), ('would', 1999), ('you', 11726), ('feel', 298), ('abou\n",
      "{'you': 1, 'what': 2, 'the': 3, 'to': 4, 'a': 5, 'your': 6, 'of': 7, 'is': 8, 'do': 9, 'that': 10, '\n",
      "11816\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "\n",
    "max_features = 40000\n",
    "\n",
    "word_tokenizer = Tokenizer(max_features)\n",
    "word_tokenizer.fit_on_texts(titles)\n",
    "\n",
    "print(str(word_tokenizer.word_counts)[0:100])\n",
    "print(str(word_tokenizer.word_index)[0:100])\n",
    "print(len(word_tokenizer.word_counts))   # true word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 19, 16, 1, 97, 32, 5, 394, 10, 3740, 1525, 2760, 48, 518, 4614, 29, 6298, 6299, 6300, 3741, 11, 88]\n"
     ]
    }
   ],
   "source": [
    "titles_tf = word_tokenizer.texts_to_sequences(titles)\n",
    "print(titles_tf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  16    1   97   32    5  394   10 3740 1525 2760   48  518 4614   29 6298\n",
      " 6299 6300 3741   11   88]\n"
     ]
    }
   ],
   "source": [
    "maxlen = 20\n",
    "titles_tf = sequence.pad_sequences(titles_tf, maxlen=maxlen)\n",
    "print(titles_tf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_path = 'glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.09190000e-03   3.33240000e-01   3.57430000e-01  -5.40410000e-01\n",
      "   8.20320000e-01  -4.93910000e-01  -3.25880000e-01   1.99720000e-03\n",
      "  -2.38290000e-01   3.55540000e-01  -6.06550000e-01   9.89320000e-01\n",
      "  -2.17860000e-01   1.12360000e-01   1.14940000e+00   7.32840000e-01\n",
      "   5.11820000e-01   2.92870000e-01   2.83880000e-01  -1.35900000e+00\n",
      "  -3.79510000e-01   5.09430000e-01   7.07100000e-01   6.29410000e-01\n",
      "   1.05340000e+00  -2.17560000e+00  -1.32040000e+00   4.00010000e-01\n",
      "   1.57410000e+00  -1.66000000e+00   3.77210000e+00   8.69490000e-01\n",
      "  -8.04390000e-01   1.83900000e-01  -3.43320000e-01   1.07140000e-02\n",
      "   2.39690000e-01   6.67480000e-02   7.01170000e-01  -7.37020000e-01\n",
      "   2.08770000e-01   1.15640000e-01  -1.51900000e-01   8.59080000e-01\n",
      "   2.26200000e-01   1.65190000e-01   3.63090000e-01  -4.56970000e-01\n",
      "  -4.89690000e-02   1.13160000e+00]\n"
     ]
    }
   ],
   "source": [
    "embedding_vectors = {}\n",
    "\n",
    "with open(embeddings_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line_split = line.strip().split(\" \")\n",
    "        vec = np.array(line_split[1:], dtype=float)\n",
    "        word = line_split[0]\n",
    "        embedding_vectors[word] = vec\n",
    "        \n",
    "print(embedding_vectors['you'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [ -1.09190000e-03   3.33240000e-01   3.57430000e-01  -5.40410000e-01\n",
      "    8.20320000e-01  -4.93910000e-01  -3.25880000e-01   1.99720000e-03\n",
      "   -2.38290000e-01   3.55540000e-01  -6.06550000e-01   9.89320000e-01\n",
      "   -2.17860000e-01   1.12360000e-01   1.14940000e+00   7.32840000e-01\n",
      "    5.11820000e-01   2.92870000e-01   2.83880000e-01  -1.35900000e+00\n",
      "   -3.79510000e-01   5.09430000e-01   7.07100000e-01   6.29410000e-01\n",
      "    1.05340000e+00  -2.17560000e+00  -1.32040000e+00   4.00010000e-01\n",
      "    1.57410000e+00  -1.66000000e+00   3.77210000e+00   8.69490000e-01\n",
      "   -8.04390000e-01   1.83900000e-01  -3.43320000e-01   1.07140000e-02\n",
      "    2.39690000e-01   6.67480000e-02   7.01170000e-01  -7.37020000e-01\n",
      "    2.08770000e-01   1.15640000e-01  -1.51900000e-01   8.59080000e-01\n",
      "    2.26200000e-01   1.65190000e-01   3.63090000e-01  -4.56970000e-01\n",
      "   -4.89690000e-02   1.13160000e+00]]\n"
     ]
    }
   ],
   "source": [
    "weights_matrix = np.zeros((max_features + 1, 50))\n",
    "\n",
    "for word, i in word_tokenizer.word_index.items():\n",
    "\n",
    "    embedding_vector = embedding_vectors.get(word)\n",
    "    if embedding_vector is not None and i <= max_features:\n",
    "        weights_matrix[i] = embedding_vector\n",
    "\n",
    "# index 0 vector should be all zeroes, index 1 vector should be the same one as above\n",
    "print(weights_matrix[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[261 263 266 271 255 300 274 258 271 295]\n"
     ]
    }
   ],
   "source": [
    "dayofyears_tf = dayofyears\n",
    "print(dayofyears_tf[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Input, Model\n",
    "from keras.layers import Dense, Embedding, GlobalAveragePooling1D, concatenate, Activation\n",
    "from keras.layers.core import Masking, Dropout, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "epochs = 20\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles_input = Input(shape=(maxlen,), name='titles_input')\n",
    "titles_embedding = Embedding(max_features + 1, embedding_dims, weights=[weights_matrix])(titles_input)\n",
    "titles_pooling = GlobalAveragePooling1D()(titles_embedding)\n",
    "titles_dropout = Dropout(dropout_rate)(titles_pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aux_output = Dense(1, activation='sigmoid', name='aux_out')(titles_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_embedding_dims = 64\n",
    "\n",
    "hours_input = Input(shape=(1,), name='hours_input')\n",
    "hours_embedding = Embedding(24, meta_embedding_dims)(hours_input)\n",
    "hours_reshape = Reshape((meta_embedding_dims,))(hours_embedding)\n",
    "\n",
    "dayofweeks_input = Input(shape=(1,), name='dayofweeks_input')\n",
    "dayofweeks_embedding = Embedding(7, meta_embedding_dims)(dayofweeks_input)\n",
    "dayofweeks_reshape = Reshape((meta_embedding_dims,))(dayofweeks_embedding)\n",
    "\n",
    "minutes_input = Input(shape=(1,), name='minutes_input')\n",
    "minutes_embedding = Embedding(60, meta_embedding_dims)(minutes_input)\n",
    "minutes_reshape = Reshape((meta_embedding_dims,))(minutes_embedding)\n",
    "\n",
    "dayofyears_input = Input(shape=(1,), name='dayofyears_input')\n",
    "dayofyears_embedding = Embedding(366, meta_embedding_dims)(dayofyears_input)\n",
    "dayofyears_reshape = Reshape((meta_embedding_dims,))(dayofyears_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = concatenate([titles_dropout, hours_reshape, dayofweeks_reshape, minutes_reshape, dayofyears_reshape])\n",
    "\n",
    "hidden_1 = Dense(256, activation='relu')(merged)\n",
    "hidden_1 = BatchNormalization()(hidden_1)\n",
    "\n",
    "main_output = Dense(1, activation='sigmoid', name='main_out')(hidden_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "titles_input (InputLayer)       (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 50)       2000050     titles_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "hours_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dayofweeks_input (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "minutes_input (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dayofyears_input (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 50)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 64)        1536        hours_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 64)        448         dayofweeks_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 64)        3840        minutes_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 64)        23424       dayofyears_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50)           0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 64)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 64)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 64)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 64)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 306)          0           dropout_1[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          78592       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_out (Dense)                (None, 1)            257         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "aux_out (Dense)                 (None, 1)            51          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,109,222\n",
      "Trainable params: 2,108,710\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[titles_input,\n",
    "                      hours_input,\n",
    "                      dayofweeks_input,\n",
    "                      minutes_input,\n",
    "                      dayofyears_input], outputs=[main_output, aux_output])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'],\n",
    "              loss_weights=[1, 0.2])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed(123)\n",
    "split = 0.2\n",
    "\n",
    "# returns randomized indices with no repeats\n",
    "idx = sample(range(titles_tf.shape[0]), titles_tf.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles_tf = titles_tf[idx, :]\n",
    "hours = hours[idx]\n",
    "dayofweeks = dayofweeks[idx]\n",
    "minutes = minutes[idx]\n",
    "dayofyears_tf = dayofyears_tf[idx]\n",
    "is_top_submission = is_top_submission[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4990625\n"
     ]
    }
   ],
   "source": [
    "print(1 - np.mean(is_top_submission[:(int(titles_tf.shape[0] * split))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger,EarlyStopping\n",
    "\n",
    "csv_logger = CSVLogger('training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 403150 samples, validate on 100788 samples\n",
      "Epoch 1/20\n",
      "403150/403150 [==============================] - 131s 326us/step - loss: 0.7311 - main_out_loss: 0.6077 - aux_out_loss: 0.6167 - main_out_acc: 0.6383 - aux_out_acc: 0.6357 - val_loss: 0.7022 - val_main_out_loss: 0.5827 - val_aux_out_loss: 0.5975 - val_main_out_acc: 0.6617 - val_aux_out_acc: 0.6516\n",
      "Epoch 2/20\n",
      "403150/403150 [==============================] - 130s 322us/step - loss: 0.7000 - main_out_loss: 0.5813 - aux_out_loss: 0.5934 - main_out_acc: 0.6632 - aux_out_acc: 0.6587 - val_loss: 0.6977 - val_main_out_loss: 0.5785 - val_aux_out_loss: 0.5958 - val_main_out_acc: 0.6656 - val_aux_out_acc: 0.6583\n",
      "Epoch 3/20\n",
      "403150/403150 [==============================] - 129s 321us/step - loss: 0.6887 - main_out_loss: 0.5713 - aux_out_loss: 0.5869 - main_out_acc: 0.6722 - aux_out_acc: 0.6667 - val_loss: 0.6952 - val_main_out_loss: 0.5759 - val_aux_out_loss: 0.5962 - val_main_out_acc: 0.6652 - val_aux_out_acc: 0.6586\n",
      "Epoch 4/20\n",
      "403150/403150 [==============================] - 131s 324us/step - loss: 0.6809 - main_out_loss: 0.5643 - aux_out_loss: 0.5827 - main_out_acc: 0.6793 - aux_out_acc: 0.6721 - val_loss: 0.6960 - val_main_out_loss: 0.5765 - val_aux_out_loss: 0.5971 - val_main_out_acc: 0.6655 - val_aux_out_acc: 0.6590\n",
      "Epoch 5/20\n",
      "403150/403150 [==============================] - 131s 326us/step - loss: 0.6752 - main_out_loss: 0.5592 - aux_out_loss: 0.5800 - main_out_acc: 0.6839 - aux_out_acc: 0.6751 - val_loss: 0.6968 - val_main_out_loss: 0.5771 - val_aux_out_loss: 0.5983 - val_main_out_acc: 0.6647 - val_aux_out_acc: 0.6611\n",
      "Epoch 6/20\n",
      "403150/403150 [==============================] - 130s 322us/step - loss: 0.6696 - main_out_loss: 0.5541 - aux_out_loss: 0.5775 - main_out_acc: 0.6891 - aux_out_acc: 0.6781 - val_loss: 0.6978 - val_main_out_loss: 0.5778 - val_aux_out_loss: 0.5997 - val_main_out_acc: 0.6630 - val_aux_out_acc: 0.6560\n",
      "Epoch 7/20\n",
      "403150/403150 [==============================] - 131s 324us/step - loss: 0.6654 - main_out_loss: 0.5503 - aux_out_loss: 0.5755 - main_out_acc: 0.6924 - aux_out_acc: 0.6805 - val_loss: 0.6986 - val_main_out_loss: 0.5785 - val_aux_out_loss: 0.6004 - val_main_out_acc: 0.6652 - val_aux_out_acc: 0.6582\n",
      "Epoch 8/20\n",
      "403150/403150 [==============================] - 130s 324us/step - loss: 0.6614 - main_out_loss: 0.5466 - aux_out_loss: 0.5740 - main_out_acc: 0.6972 - aux_out_acc: 0.6830 - val_loss: 0.7007 - val_main_out_loss: 0.5802 - val_aux_out_loss: 0.6021 - val_main_out_acc: 0.6643 - val_aux_out_acc: 0.6594\n",
      "Epoch 9/20\n",
      "403150/403150 [==============================] - 131s 325us/step - loss: 0.6573 - main_out_loss: 0.5428 - aux_out_loss: 0.5724 - main_out_acc: 0.6998 - aux_out_acc: 0.6849 - val_loss: 0.7030 - val_main_out_loss: 0.5826 - val_aux_out_loss: 0.6023 - val_main_out_acc: 0.6629 - val_aux_out_acc: 0.6576\n",
      "Epoch 10/20\n",
      "403150/403150 [==============================] - 130s 323us/step - loss: 0.6541 - main_out_loss: 0.5398 - aux_out_loss: 0.5713 - main_out_acc: 0.7030 - aux_out_acc: 0.6861 - val_loss: 0.7046 - val_main_out_loss: 0.5840 - val_aux_out_loss: 0.6033 - val_main_out_acc: 0.6631 - val_aux_out_acc: 0.6567\n",
      "Epoch 11/20\n",
      "403150/403150 [==============================] - 131s 326us/step - loss: 0.6500 - main_out_loss: 0.5360 - aux_out_loss: 0.5700 - main_out_acc: 0.7055 - aux_out_acc: 0.6871 - val_loss: 0.7058 - val_main_out_loss: 0.5849 - val_aux_out_loss: 0.6043 - val_main_out_acc: 0.6613 - val_aux_out_acc: 0.6546\n",
      "Epoch 12/20\n",
      "403150/403150 [==============================] - 132s 329us/step - loss: 0.6473 - main_out_loss: 0.5334 - aux_out_loss: 0.5693 - main_out_acc: 0.7081 - aux_out_acc: 0.6879 - val_loss: 0.7073 - val_main_out_loss: 0.5863 - val_aux_out_loss: 0.6052 - val_main_out_acc: 0.6623 - val_aux_out_acc: 0.6548\n",
      "Epoch 13/20\n",
      "403150/403150 [==============================] - 131s 325us/step - loss: 0.6435 - main_out_loss: 0.5298 - aux_out_loss: 0.5686 - main_out_acc: 0.7115 - aux_out_acc: 0.6890 - val_loss: 0.7078 - val_main_out_loss: 0.5868 - val_aux_out_loss: 0.6052 - val_main_out_acc: 0.6611 - val_aux_out_acc: 0.6565\n",
      "Epoch 14/20\n",
      "403150/403150 [==============================] - 132s 327us/step - loss: 0.6401 - main_out_loss: 0.5265 - aux_out_loss: 0.5679 - main_out_acc: 0.7140 - aux_out_acc: 0.6892 - val_loss: 0.7136 - val_main_out_loss: 0.5924 - val_aux_out_loss: 0.6061 - val_main_out_acc: 0.6595 - val_aux_out_acc: 0.6536\n",
      "Epoch 15/20\n",
      "403150/403150 [==============================] - 131s 325us/step - loss: 0.6364 - main_out_loss: 0.5230 - aux_out_loss: 0.5671 - main_out_acc: 0.7165 - aux_out_acc: 0.6900 - val_loss: 0.7130 - val_main_out_loss: 0.5917 - val_aux_out_loss: 0.6066 - val_main_out_acc: 0.6579 - val_aux_out_acc: 0.6531\n",
      "Epoch 16/20\n",
      "403150/403150 [==============================] - 131s 326us/step - loss: 0.6332 - main_out_loss: 0.5199 - aux_out_loss: 0.5663 - main_out_acc: 0.7190 - aux_out_acc: 0.6910 - val_loss: 0.7189 - val_main_out_loss: 0.5973 - val_aux_out_loss: 0.6080 - val_main_out_acc: 0.6554 - val_aux_out_acc: 0.6552\n",
      "Epoch 17/20\n",
      "403150/403150 [==============================] - 131s 324us/step - loss: 0.6301 - main_out_loss: 0.5169 - aux_out_loss: 0.5658 - main_out_acc: 0.7224 - aux_out_acc: 0.6919 - val_loss: 0.7204 - val_main_out_loss: 0.5987 - val_aux_out_loss: 0.6086 - val_main_out_acc: 0.6582 - val_aux_out_acc: 0.6544\n",
      "Epoch 18/20\n",
      "403150/403150 [==============================] - 130s 323us/step - loss: 0.6265 - main_out_loss: 0.5134 - aux_out_loss: 0.5653 - main_out_acc: 0.7250 - aux_out_acc: 0.6918 - val_loss: 0.7287 - val_main_out_loss: 0.6067 - val_aux_out_loss: 0.6102 - val_main_out_acc: 0.6540 - val_aux_out_acc: 0.6557\n",
      "Epoch 19/20\n",
      "403150/403150 [==============================] - 132s 327us/step - loss: 0.6220 - main_out_loss: 0.5090 - aux_out_loss: 0.5648 - main_out_acc: 0.7283 - aux_out_acc: 0.6923 - val_loss: 0.7278 - val_main_out_loss: 0.6059 - val_aux_out_loss: 0.6098 - val_main_out_acc: 0.6574 - val_aux_out_acc: 0.6556\n",
      "Epoch 20/20\n",
      "403150/403150 [==============================] - 130s 323us/step - loss: 0.6180 - main_out_loss: 0.5052 - aux_out_loss: 0.5643 - main_out_acc: 0.7314 - aux_out_acc: 0.6926 - val_loss: 0.7308 - val_main_out_loss: 0.6091 - val_aux_out_loss: 0.6089 - val_main_out_acc: 0.6571 - val_aux_out_acc: 0.6538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b3c69e6a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([titles_tf, hours, dayofweeks, minutes, dayofyears_tf], [is_top_submission, is_top_submission],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=split, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_text(text, maxlen):\n",
    "    encoded = word_tokenizer.texts_to_sequences([text])\n",
    "    return sequence.pad_sequences(encoded, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0   66  696   16 1734  157   23    1\n",
      "  2141    5  884   48  374  340]]\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Which movie's plot would drastically change if you removed a letter from its title?\"\n",
    "encoded_text = encode_text(input_text, maxlen)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.00543976]], dtype=float32), array([[ 0.26231879]], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_hour = np.array([15])\n",
    "input_minute = np.array([10])\n",
    "input_dayofweek = np.array([1])\n",
    "input_dayofyear = np.array([16 - 1])\n",
    "\n",
    "model.predict([encoded_text, input_hour, input_dayofweek, input_minute, input_dayofyear])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('What', 'WP'), ('is', 'VBZ'), ('that', 'DT'), ('one', 'CD'), ('thing', 'NN'), ('that', 'WDT'), ('immediately', 'RB'), ('puts', 'VBZ'), ('you', 'PRP'), ('off', 'RP'), ('a', 'DT'), ('person', 'NN'), ('?', '.')]\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What is that one thing that immediately puts you off a person?\"\n",
    "\n",
    "tokens = nltk.word_tokenize(input_text)\n",
    "pos = nltk.pos_tag(tokens)\n",
    "\n",
    "print(pos)\n",
    "\n",
    "word_list = input_text.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def deleteWord(word_list):\n",
    "    temp_list = word_list[:]\n",
    "    final_text = \"\"\n",
    "    max_score = int(0)\n",
    "    for i in range(len(word_list)):\n",
    "        temp_list = word_list[:]\n",
    "        if(pos[i][1]=='JJ' or po s[i][1]=='JJR' or pos[i][1]=='JJS' or pos[i][1]=='RB' or pos[i][1]=='RBR' or pos[i][1]=='RBS'):\n",
    "            if(i != 0 and i != len(word_list)-1 ): # probably not gonna remove first word and last word\n",
    "                del temp_list[i]\n",
    "                temp_text = \" \".join(temp_list)\n",
    "                encoded_text = encode_text(temp_text, maxlen)\n",
    "                predict_score = model.predict([encoded_text, input_hour, input_dayofweek, input_minute, input_dayofyear])\n",
    "                print(temp_list,predict_score[1][0])\n",
    "\n",
    "                if (max_score - predict_score[1][0][0] < 0):\n",
    "                    max_score = predict_score[1][0][0]\n",
    "                    final_text = temp_text\n",
    "    word_BeforeChange = \" \".join(word_list)\n",
    "    print(\"\\nBefore Chanege : \",word_BeforeChange, \"[\", predict_score_B[0][0][0], \"]\")\n",
    "    print(\"After Change : \",final_text, \"[\", max_score,\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'is', 'that', 'one', 'thing', 'that', 'puts', 'you', 'off', 'a', 'person?'] [ 0.40537578]\n",
      "\n",
      "Before Chanege :  What is that one thing that immediately puts you off a person? [ 0.556207 ]\n",
      "After Change :  What is that one thing that puts you off a person? [ 0.405376 ]\n"
     ]
    }
   ],
   "source": [
    "deleteWord(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def synonym(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lm in syn.lemmas():\n",
    "            synonyms.append(lm.name())\n",
    "    return list(set(synonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cost',\n",
       " 'exist',\n",
       " 'equal',\n",
       " 'be',\n",
       " 'embody',\n",
       " 'follow',\n",
       " 'make_up',\n",
       " 'comprise',\n",
       " 'personify',\n",
       " 'live',\n",
       " 'represent',\n",
       " 'constitute']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym('is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grammar_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grammarbot import GrammarBotClient\n",
    "client = GrammarBotClient(api_key='9JMF2Y5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace a word with a synonym word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replaceWord(word_list):\n",
    "    temp_list = word_list[:]\n",
    "    final_text = \"\"\n",
    "    max_score = int(0)\n",
    "    # tool = grammar_check.LanguageTool('en-GB')\n",
    "    for i in range(len(word_list)):\n",
    "        syno = synonym(temp_list[i])\n",
    "        possyn = nltk.pos_tag(syno)\n",
    "    #     print(possyn)\n",
    "        for j in range(len(syno)):\n",
    "    #         if(pos[i][1] == possyn[j][1]):\n",
    "                temp_list = word_list[:]\n",
    "                temp_list[i] = syno[j]\n",
    "                encoded_text = encode_text(temp_list, maxlen)\n",
    "                predict_score = model.predict([encoded_text, input_hour, input_dayofweek, input_minute, input_dayofyear])\n",
    "                temp_text = \" \".join(temp_list)\n",
    "                print(temp_text,predict_score[1][0])\n",
    "    #             res = client.check(temp_text)\n",
    "    #             matches = tool.check(temp_text)\n",
    "    #             print(\"gramma check matches:\",len(res.matches))\n",
    "\n",
    "                if (max_score - predict_score[1][0][0] < 0):\n",
    "                    max_score = predict_score[1][0][0]\n",
    "                    temp_text = \" \".join(temp_list)\n",
    "                    final_text = temp_text\n",
    "\n",
    "    word_BeforeChange = \" \".join(word_list)\n",
    "    print(\"\\nBefore Change : \",word_BeforeChange, \"[\", predict_score_B[0][0][0],\"]\")\n",
    "    print(\"After Change : \",final_text, \"[\", max_score,\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What cost that one thing that immediately puts you off a person? [ 0.18989711]\n",
      "What exist that one thing that immediately puts you off a person? [ 0.23831394]\n",
      "What equal that one thing that immediately puts you off a person? [ 0.19243886]\n",
      "What be that one thing that immediately puts you off a person? [ 0.29819027]\n",
      "What embody that one thing that immediately puts you off a person? [ 0.20281577]\n",
      "What follow that one thing that immediately puts you off a person? [ 0.229223]\n",
      "What make_up that one thing that immediately puts you off a person? [ 0.20281577]\n",
      "What comprise that one thing that immediately puts you off a person? [ 0.20281577]\n",
      "What personify that one thing that immediately puts you off a person? [ 0.20281577]\n",
      "What live that one thing that immediately puts you off a person? [ 0.15165661]\n",
      "What represent that one thing that immediately puts you off a person? [ 0.12616616]\n",
      "What constitute that one thing that immediately puts you off a person? [ 0.20281577]\n",
      "What is that ace thing that immediately puts you off a person? [ 0.21126632]\n",
      "What is that 1 thing that immediately puts you off a person? [ 0.18113095]\n",
      "What is that ane thing that immediately puts you off a person? [ 0.21126632]\n",
      "What is that unitary thing that immediately puts you off a person? [ 0.21126632]\n",
      "What is that unmatched thing that immediately puts you off a person? [ 0.21126632]\n",
      "What is that unrivalled thing that immediately puts you off a person? [ 0.21126632]\n",
      "What is that nonpareil thing that immediately puts you off a person? [ 0.21126632]\n",
      "What is that i thing that immediately puts you off a person? [ 0.19867615]\n",
      "What is that matchless thing that immediately puts you off a person? [ 0.21126632]\n",
      "What is that I thing that immediately puts you off a person? [ 0.21126632]\n",
      "What is that single thing that immediately puts you off a person? [ 0.23267475]\n",
      "What is that unmatchable thing that immediately puts you off a person? [ 0.21126632]\n",
      "What is that unity thing that immediately puts you off a person? [ 0.21126632]\n",
      "What is that one_and_only thing that immediately puts you off a person? [ 0.21126632]\n",
      "What is that one thing that immediately puts you off a person? [ 0.20488293]\n",
      "What is that peerless thing that immediately puts you off a person? [ 0.21126632]\n",
      "What is that unrivaled thing that immediately puts you off a person? [ 0.07046681]\n",
      "What is that one matter that immediately puts you off a person? [ 0.15708598]\n",
      "What is that one thing that immediately puts you off a person? [ 0.20488293]\n",
      "What is that one affair that immediately puts you off a person? [ 0.20760892]\n",
      "What is that one thing that like_a_shot puts you off a person? [ 0.19257097]\n",
      "What is that one thing that immediately puts you off a person? [ 0.20488293]\n",
      "What is that one thing that instantly puts you off a person? [ 0.21028507]\n",
      "What is that one thing that straight_off puts you off a person? [ 0.19257097]\n",
      "What is that one thing that right_away puts you off a person? [ 0.19257097]\n",
      "What is that one thing that forthwith puts you off a person? [ 0.19257097]\n",
      "What is that one thing that at_once puts you off a person? [ 0.19257097]\n",
      "What is that one thing that now puts you off a person? [ 0.16772498]\n",
      "What is that one thing that directly puts you off a person? [ 0.19387463]\n",
      "What is that one thing that straightaway puts you off a person? [ 0.19257097]\n",
      "What is that one thing that immediately cast you off a person? [ 0.19696541]\n",
      "What is that one thing that immediately couch you off a person? [ 0.07989639]\n",
      "What is that one thing that immediately set you off a person? [ 0.20100285]\n",
      "What is that one thing that immediately pose you off a person? [ 0.12838466]\n",
      "What is that one thing that immediately assign you off a person? [ 0.36063972]\n",
      "What is that one thing that immediately order you off a person? [ 0.30528498]\n",
      "What is that one thing that immediately set_up you off a person? [ 0.21353339]\n",
      "What is that one thing that immediately put_option you off a person? [ 0.21353339]\n",
      "What is that one thing that immediately position you off a person? [ 0.19789337]\n",
      "What is that one thing that immediately frame you off a person? [ 0.31165072]\n",
      "What is that one thing that immediately put you off a person? [ 0.22699934]\n",
      "What is that one thing that immediately redact you off a person? [ 0.21353339]\n",
      "What is that one thing that immediately commit you off a person? [ 0.23886086]\n",
      "What is that one thing that immediately invest you off a person? [ 0.12168035]\n",
      "What is that one thing that immediately arrange you off a person? [ 0.21353339]\n",
      "What is that one thing that immediately lay you off a person? [ 0.08097944]\n",
      "What is that one thing that immediately place you off a person? [ 0.17774722]\n",
      "What is that one thing that immediately puts you cancelled a person? [ 0.20211497]\n",
      "What is that one thing that immediately puts you bump_off a person? [ 0.23135616]\n",
      "What is that one thing that immediately puts you murder a person? [ 0.25005889]\n",
      "What is that one thing that immediately puts you hit a person? [ 0.21024504]\n",
      "What is that one thing that immediately puts you off a person? [ 0.20488293]\n",
      "What is that one thing that immediately puts you turned a person? [ 0.12254891]\n",
      "What is that one thing that immediately puts you dispatch a person? [ 0.34613866]\n",
      "What is that one thing that immediately puts you slay a person? [ 0.23135616]\n",
      "What is that one thing that immediately puts you sour a person? [ 0.1028368]\n",
      "What is that one thing that immediately puts you away a person? [ 0.20507675]\n",
      "What is that one thing that immediately puts you forth a person? [ 0.23729222]\n",
      "What is that one thing that immediately puts you polish_off a person? [ 0.23135616]\n",
      "What is that one thing that immediately puts you remove a person? [ 0.24732211]\n",
      "What is that one thing that immediately puts you off adenine person? [ 0.20482792]\n",
      "What is that one thing that immediately puts you off amp person? [ 0.24462482]\n",
      "What is that one thing that immediately puts you off group_A person? [ 0.20482792]\n",
      "What is that one thing that immediately puts you off A person? [ 0.20482792]\n",
      "What is that one thing that immediately puts you off ampere person? [ 0.20482792]\n",
      "What is that one thing that immediately puts you off angstrom_unit person? [ 0.20482792]\n",
      "What is that one thing that immediately puts you off type_A person? [ 0.20482792]\n",
      "What is that one thing that immediately puts you off antiophthalmic_factor person? [ 0.20482792]\n",
      "What is that one thing that immediately puts you off a person? [ 0.20488293]\n",
      "What is that one thing that immediately puts you off angstrom person? [ 0.20482792]\n",
      "What is that one thing that immediately puts you off deoxyadenosine_monophosphate person? [ 0.20482792]\n",
      "What is that one thing that immediately puts you off vitamin_A person? [ 0.20482792]\n",
      "What is that one thing that immediately puts you off axerophthol person? [ 0.20482792]\n",
      "\n",
      "Before Change :  What is that one thing that immediately puts you off a person? [ 0.556207 ]\n",
      "After Change :  What is that one thing that immediately assign you off a person? [ 0.36064 ]\n"
     ]
    }
   ],
   "source": [
    "replaceWord(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.collocations\n",
    "import nltk.corpus\n",
    "import collections\n",
    "\n",
    "bgm    = nltk.collocations.BigramAssocMeasures()\n",
    "finder = nltk.collocations.BigramCollocationFinder.from_words(nltk.corpus.brown.words())\n",
    "scored = finder.score_ngrams( bgm.likelihood_ratio  )\n",
    "\n",
    "# Group bigrams by first word in bigram.                                        \n",
    "suffix_keys = collections.defaultdict(list)\n",
    "for key, scores in scored:\n",
    "   suffix_keys[key[1]].append((key[0], scores))\n",
    "\n",
    "# Sort keyed bigrams by strongest association.                                  \n",
    "for key in suffix_keys:\n",
    "   suffix_keys[key].sort(key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWord(word_list):\n",
    "    temp_list = word_list[:]\n",
    "    final_text = \"\"\n",
    "    max_score = int(0)\n",
    "    # tool = grammar_check.LanguageTool('en-GB')\n",
    "    for i in range(len(word_list)):\n",
    "        if(pos[i][1]=='NN' or pos[i][1]=='NNS' or pos[i][1]=='NNP' or pos[i][1]=='NNPS' \n",
    "           or pos[i][1]=='JJ' or pos[i][1]=='JJR' or pos[i][1]=='JJS' \n",
    "           or pos[i][1]=='VB' or pos[i][1]=='VBD' or pos[i][1]=='VBG' or pos[i][1]=='VBN'):\n",
    "            if(pos[i-1][1]!='JJ' and pos[i-1][1]!='JJR' and pos[i-1][1]!='JJS' and pos[i-1][1]!='RB' and pos[i-1][1]!='RBR' and pos[i-1][1]!='RBS'):\n",
    "                prefix_list = []\n",
    "                for word in suffix_keys[temp_list[i]]:\n",
    "                    prefix_list.append(word[0])\n",
    "                pos_prefix = nltk.pos_tag(prefix_list)\n",
    "                prefix_list_select = []\n",
    "                for j in range(len(pos_prefix)):\n",
    "                    if(pos_prefix[j][1]=='JJ' or pos_prefix[j][1]=='JJR' or pos_prefix[j][1]=='JJS' or pos_prefix[j][1]=='RB' or pos_prefix[j][1]=='RBR' or pos_prefix[j][1]=='RBS'):\n",
    "                        prefix_list_select.append(pos_prefix[j])\n",
    "                for prefix in prefix_list_select:\n",
    "                    temp_list.insert(i,prefix[0])\n",
    "                    encoded_text = encode_text(temp_list, maxlen)\n",
    "                    predict_score = model.predict([encoded_text, input_hour, input_dayofweek, input_minute, input_dayofyear])\n",
    "                    temp_text = \" \".join(temp_list)\n",
    "                    temp_list = word_list[:]\n",
    "                    print(temp_text,predict_score[1][0])\n",
    "                    if (max_score - predict_score[1][0][0] < 0):\n",
    "                        max_score = predict_score[1][0][0]\n",
    "                        final_text = temp_text\n",
    "\n",
    "    word_BeforeChange = \" \".join(word_list)\n",
    "    print(\"\\nBefore Change : \",word_BeforeChange, \"[\", predict_score_B[0][0][0],\"]\")\n",
    "    print(\"After Change : \",final_text, \"[\", max_score,\"]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is that one same thing that immediately puts you off a person? [ 0.24807252]\n",
      "What is that one important thing that immediately puts you off a person? [ 0.2317185]\n",
      "What is that one only thing that immediately puts you off a person? [ 0.23635107]\n",
      "What is that one whole thing that immediately puts you off a person? [ 0.21685261]\n",
      "What is that one first thing that immediately puts you off a person? [ 0.20137316]\n",
      "What is that one good thing that immediately puts you off a person? [ 0.21114784]\n",
      "What is that one real thing that immediately puts you off a person? [ 0.19737232]\n",
      "What is that one bad thing that immediately puts you off a person? [ 0.21253607]\n",
      "What is that one such thing that immediately puts you off a person? [ 0.21849221]\n",
      "What is that one terrible thing that immediately puts you off a person? [ 0.07866835]\n",
      "What is that one easiest thing that immediately puts you off a person? [ 0.22514383]\n",
      "What is that one little thing that immediately puts you off a person? [ 0.20934989]\n",
      "What is that one nicest thing that immediately puts you off a person? [ 0.1431665]\n",
      "What is that one wonderful thing that immediately puts you off a person? [ 0.140981]\n",
      "What is that one unusual thing that immediately puts you off a person? [ 0.17523597]\n",
      "What is that one unheard-of thing that immediately puts you off a person? [ 0.20488293]\n",
      "What is that one wrong thing that immediately puts you off a person? [ 0.21258272]\n",
      "What is that one unbelievable thing that immediately puts you off a person? [ 0.10981324]\n",
      "What is that one nasty thing that immediately puts you off a person? [ 0.10063737]\n",
      "What is that one difficult thing that immediately puts you off a person? [ 0.24673946]\n",
      "What is that one last thing that immediately puts you off a person? [ 0.222352]\n",
      "What is that one man-made thing that immediately puts you off a person? [ 0.20488293]\n",
      "What is that one expedient thing that immediately puts you off a person? [ 0.20488293]\n",
      "What is that one fastest thing that immediately puts you off a person? [ 0.24019256]\n",
      "What is that one dreadful thing that immediately puts you off a person? [ 0.20488293]\n",
      "What is that one childish thing that immediately puts you off a person? [ 0.20403878]\n",
      "What is that one fearful thing that immediately puts you off a person? [ 0.20488293]\n",
      "What is that one handy thing that immediately puts you off a person? [ 0.18641341]\n",
      "What is that one horrible thing that immediately puts you off a person? [ 0.21349253]\n",
      "What is that one silly thing that immediately puts you off a person? [ 0.15339386]\n",
      "What is that one awful thing that immediately puts you off a person? [ 0.22054674]\n",
      "What is that one notable thing that immediately puts you off a person? [ 0.47833255]\n",
      "What is that one noble thing that immediately puts you off a person? [ 0.20488293]\n",
      "What is that one unexpected thing that immediately puts you off a person? [ 0.31017905]\n",
      "What is that one surprising thing that immediately puts you off a person? [ 0.25034386]\n",
      "What is that one routine thing that immediately puts you off a person? [ 0.18220462]\n",
      "What is that one worst thing that immediately puts you off a person? [ 0.22869182]\n",
      "What is that one funny thing that immediately puts you off a person? [ 0.21160692]\n",
      "What is that one small thing that immediately puts you off a person? [ 0.21722682]\n",
      "What is that one remarkable thing that immediately puts you off a person? [ 0.20488293]\n",
      "What is that one right thing that immediately puts you off a person? [ 0.20862305]\n",
      "What is that one excellent thing that immediately puts you off a person? [ 0.20488293]\n",
      "What is that one characteristic thing that immediately puts you off a person? [ 0.26205224]\n",
      "What is that one greatest thing that immediately puts you off a person? [ 0.20742887]\n",
      "What is that one very thing that immediately puts you off a person? [ 0.21141447]\n",
      "What is that one main thing that immediately puts you off a person? [ 0.22887161]\n",
      "What is that one similar thing that immediately puts you off a person? [ 0.18480663]\n",
      "What is that one new thing that immediately puts you off a person? [ 0.2073094]\n",
      "What is that one hard thing that immediately puts you off a person? [ 0.2030417]\n",
      "What is that one common thing that immediately puts you off a person? [ 0.19324282]\n",
      "What is that one big thing that immediately puts you off a person? [ 0.2354161]\n",
      "What is that one best thing that immediately puts you off a person? [ 0.20363566]\n",
      "What is that one next thing that immediately puts you off a person? [ 0.18010622]\n",
      "What is that one possible thing that immediately puts you off a person? [ 0.15521125]\n",
      "What is that one more thing that immediately puts you off a person? [ 0.19322282]\n",
      "\n",
      "Before Change :  What is that one thing that immediately puts you off a person? [ 0.556207 ]\n",
      "After Change :  What is that one notable thing that immediately puts you off a person? [ 0.478333 ]\n"
     ]
    }
   ],
   "source": [
    "addWord(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
